{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling sequence learning\n",
    "\n",
    "As in Whittington et al. (2020), we model the spatial task of predicting the next location in a trajectory as the prediction of the next node in a graph. We create a large set of graphs, each one an n-by-n grid of nodes representing a simple spatial environment. Nodes are labelled with random letters to represent arbitrary associations at a particular location. Each directed edge, i.e. each possible transition in the graph, is of the type north, south, east, or west. Random walks in the set of graphs are used to train the model; these could represent sequences stored in an initial bank of memories. The generative model is trained from scratch on the replayed sequences (converted to strings of the form ‘node1 E node2 W node3 …’) with the mechanism of causal language modelling.\n",
    "\n",
    "This is a Colab version of the original notebook; to run this outside of Colab, please use the version in the shapes_vae directory.\n",
    "\n",
    "This code will only work with access to a GPU. To switch to GPU on Colab, go to 'Runtime' > 'Change runtime type', and select 'GPU' from the 'Hardware acceleration' dropdown menu. (Note that the free version of Colab will only allow this for one notebook at a time.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colab installation:\n",
    "\n",
    "Make sure you click 'Restart runtime' after running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install simpletransformers csrgraph networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import csrgraph as cg\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from simpletransformers.language_modeling import (\n",
    "    LanguageModelingModel,\n",
    "    LanguageModelingArgs,\n",
    ")\n",
    "from simpletransformers.language_generation import (\n",
    "    LanguageGenerationModel, \n",
    "    LanguageGenerationArgs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare training data\n",
    "\n",
    "The function below takes a list of node names (which could represent arbitrary characteristics of points in space) and constructs a directed graph in the shape of a 3X3 grid. Each transition / edge is either north, south, east or west (i.e. N, S, E, or W)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(nodes = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\"]):\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    east_pairs = [(nodes[0], nodes[1]), (nodes[1], nodes[2]), (nodes[3], nodes[4]), \n",
    "                  (nodes[4], nodes[5]), (nodes[6], nodes[7]), (nodes[7], nodes[8])]\n",
    "    south_pairs = [(nodes[0], nodes[3]), (nodes[3], nodes[6]), (nodes[1], nodes[4]), \n",
    "                   (nodes[4], nodes[7]), (nodes[2], nodes[5]), (nodes[5], nodes[8])]\n",
    "    north_pairs = [(i[1], i[0]) for i in south_pairs]\n",
    "    west_pairs = [(i[1], i[0]) for i in east_pairs]\n",
    "\n",
    "    for n in nodes:\n",
    "        G.add_node(n)\n",
    "\n",
    "    for tple in east_pairs:\n",
    "        G.add_edge(tple[0], tple[1], direction='E')\n",
    "    for tple in north_pairs:\n",
    "        G.add_edge(tple[0], tple[1], direction='N')\n",
    "    for tple in west_pairs:\n",
    "        G.add_edge(tple[0], tple[1], direction='W')\n",
    "    for tple in south_pairs:\n",
    "        G.add_edge(tple[0], tple[1], direction='S')\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple function to plot the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_G(G):\n",
    "    pos = nx.spring_layout(G, iterations=100, seed=39775)\n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "\n",
    "    nx.draw(G, pos, ax=ax, font_size=8, with_labels=True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#plot_G(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get random walks of length 50 from a given graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_walks(G):\n",
    "    csr_G = cg.csrgraph(G, threads=12) \n",
    "    node_names = csr_G.names\n",
    "    walks = csr_G.random_walks(walklen=50, # length of the walks\n",
    "                    epochs=10, \n",
    "                    start_nodes=None, \n",
    "                    return_weight=1.,\n",
    "                    neighbor_weight=1.)\n",
    "\n",
    "    walks = np.vectorize(lambda x: node_names[x])(walks)\n",
    "    return walks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below:\n",
    "* Defines a function to convert a random walk into a string (e.g. 'node1 E node2 W node3 ...')\n",
    "* Defines a function to pull all this together, by random selecting 9 letters as arbitrary node names, creating a 3X3 grid graph with these nodes, getting random walks in this graph, and converting them to strings\n",
    "* Runs this final function to gather the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_to_string(walk, G):\n",
    "    walk_string = \"\"\n",
    "    for i in range(len(walk)-1):\n",
    "        node1 = walk[i]\n",
    "        node2 = walk[i+1]\n",
    "        direc = G.edges[(node1, node2)]['direction']\n",
    "        walk_string += str(node1) + \" \"+ str(direc) + \" \"\n",
    "    walk_string += walk[-1]\n",
    "    return walk_string\n",
    "\n",
    "def get_walks_as_strings():\n",
    "    entities_for_graphs =[[random.choice(string.ascii_letters[0:26]) for i in range(9)] for i in range(1000)]\n",
    "    entities_for_graphs = [entities for entities in entities_for_graphs if len(list(set(entities)))== 9]\n",
    "\n",
    "    walks_as_strings = []\n",
    "    for nodes in entities_for_graphs:\n",
    "        G = get_graph(nodes=nodes)\n",
    "        walks = get_random_walks(G)\n",
    "        walks_as_strings.extend([walk_to_string(walk, G) for walk in walks])\n",
    "    return walks_as_strings\n",
    "\n",
    "walks_as_strings = get_walks_as_strings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train generative model\n",
    "\n",
    "Train GPT-2 from scratch on dataset created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "model_args = LanguageModelingArgs()\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.num_train_epochs = 10\n",
    "model_args.dataset_type = \"simple\"\n",
    "model_args.save_model_every_epoch = False\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.mlm = False  # mlm must be False for CLM\n",
    "model_args.learning_rate = 1e-5\n",
    "model_args.vocab_size=100\n",
    "model_args.use_early_stopping = True\n",
    "model_args.manual_seed = 123\n",
    "\n",
    "text_file = open(\"train.txt\", \"w\")\n",
    "walks = get_walks_as_strings()[0:10000]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"test.txt\", \"w\")\n",
    "walks = get_walks_as_strings()[0:1000]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "train_file = \"train.txt\"\n",
    "test_file = \"test.txt\"\n",
    "\n",
    "model = LanguageModelingModel(\n",
    "    \"gpt2\", None, train_files='train.txt', args=model_args\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_file, eval_file=test_file)\n",
    "\n",
    "# Evaluate the model\n",
    "result = model.eval_model(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load trained model for sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageGenerationModel(\"gpt2\", \"outputs\", args={'do_sample': False, 'evaluate_generated_text': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate(\"a E b S e W d N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any spatial environment, going N, E, S, W by one unit each takes you back to your starting point. Can the model perform structural inference to predict the next node in this way?\n",
    "\n",
    "Let's start by specifying the set of 4-transition cycles / loops in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loops = [\"{} E {} S {} W {} N\", \"{} S {} W {} N {} E\", \"{} W {} N {} E {} S\", \"{} N {} E {} S {} W\",\n",
    "        \"{} E {} N {} W {} S\", \"{} N {} W {} S {} E\", \"{} W {} S {} E {} N\", \"{} S {} E {} N {} W\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop():\n",
    "    random_nodes = [random.choice(string.ascii_letters[0:26]) for i in range(4)]\n",
    "    loop = random.choice(loops)\n",
    "    test_string = loop.format(random_nodes[0], random_nodes[1], random_nodes[2], random_nodes[3])\n",
    "    output = model.generate(test_string)\n",
    "    output = output[0][0:len(test_string)+2]\n",
    "    if output[-1] == output[0]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "results = [test_loop() for i in range(100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what percentage of trials was the next node correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A more challenging test\n",
    "\n",
    "For an arbitrary loop in the graph, can the model predict the final item?\n",
    "\n",
    "Here we define a function to get all cycles (loops in the graph that only visit each node once). We then test in each case whether the GPT-2 model can infer the final node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cycles_for_graph(G):\n",
    "    cycles = nx.simple_cycles(G)\n",
    "    loops = []\n",
    "    for c in cycles:\n",
    "        path_string = \"\"\n",
    "        for ind, node in enumerate(c):\n",
    "            if ind+1 < len(c):\n",
    "                direction = G.get_edge_data(c[ind], c[ind+1])['direction']\n",
    "                path_string += '{} {} '.format(node, direction)\n",
    "            else:\n",
    "                direction = G.get_edge_data(c[ind], c[0])['direction']\n",
    "                path_string += '{} {} '.format(node, direction)\n",
    "        loops.append(path_string)\n",
    "    return loops\n",
    "\n",
    "def test_loop(num_graphs = 5):\n",
    "    results = []\n",
    "    lens = []\n",
    "    \n",
    "    for i in range(num_graphs):\n",
    "        entities_for_graphs =[[random.choice(string.ascii_letters[0:26]) for i in range(9)] for i in range(100)]\n",
    "        entities_for_graphs = [entities for entities in entities_for_graphs if len(list(set(entities)))== 9]\n",
    "        nodes = entities_for_graphs[0]\n",
    "        G = get_graph(nodes=nodes)\n",
    "        test_strings = get_cycles_for_graph(G)\n",
    "\n",
    "        for test_string in test_strings:\n",
    "            lens.append((len(test_string))/4)\n",
    "            output = model.generate(test_string)\n",
    "            output = output[0][0:len(test_string)+1]\n",
    "            if output[-1] == output[0]:\n",
    "                results.append(1)\n",
    "            else:\n",
    "                results.append(0)\n",
    "    \n",
    "    return results, lens\n",
    "\n",
    "results, lens = test_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot structural inference accuracy against graph cycle length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_for_len(length):\n",
    "    accs = [r for ind, r in enumerate(results) if lens[ind] == length]\n",
    "    return accs.count(1) / len(accs)\n",
    "\n",
    "lengths = [2, 4, 6, 8]\n",
    "accuracies = [acc_for_len(i) for i in lengths]\n",
    "\n",
    "plt.bar(lengths, accuracies)\n",
    "plt.title('Next node inference accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of transitions')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graph_cycle_length.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.rcParams.update({'font.size' : 15})\n",
    "\n",
    "df = pd.read_csv('outputs/training_progress_scores.csv')\n",
    "df = df.iloc[0:7]\n",
    "df.plot(x='global_step', y='eval_loss', title='Loss over time', \n",
    "                   ylabel='Loss on test set', xlabel = 'Training step', legend=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graph-gpt.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
