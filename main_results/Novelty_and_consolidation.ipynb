{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novelty and consolidation\n",
    "\n",
    "Code for exploring how novelty might affect memory consolidation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from end_to_end import run_end_to_end\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from utils import prepare_data, noise, display\n",
    "from initial_model import create_autoencoder\n",
    "from initial_tests import check_initial_recall, iterative_recall\n",
    "from generative_model import VAE, build_encoder_decoder_v3, build_encoder_decoder_v5\n",
    "from generative_tests import interpolate_ims, plot_latent_space, check_generative_recall, plot_history, vector_arithmetic\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import hopfield_utils\n",
    "from hopfield_models import ContinuousHopfield\n",
    "import matplotlib.backends.backend_pdf\n",
    "from config import models_dict, dims_dict\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# set tensorflow random seed to make outputs reproducible\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train VAE\n",
    "\n",
    "As a starting point, train VAE on just the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_epochs=10\n",
    "latent_dim=5\n",
    "kl_weighting=1\n",
    "dataset = 'mnist'\n",
    "lr=0.002\n",
    "\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "    \n",
    "encoder, decoder = models_dict[dataset](latent_dim = latent_dim)\n",
    "vae = VAE(encoder, decoder, kl_weighting)\n",
    "opt = keras.optimizers.Adam(lr=lr)\n",
    "vae.compile(optimizer=opt)\n",
    "history = vae.fit(mnist_digits[0:5000], epochs=generative_epochs, verbose=1, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure reconstruction error for new data\n",
    "\n",
    "We'll use 2000 unseen items from each of three datasets: MNIST, KMNIST, and Fashion MNIST.\n",
    "\n",
    "MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encs = vae.encoder.predict(mnist_digits[5000:7000])\n",
    "decs = vae.decoder.predict(encs[0])\n",
    "mnist_recons = tf.reduce_sum(keras.losses.mean_absolute_error(mnist_digits[5000:7000], decs), axis=(1,2)).numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = dims_dict[dataset]\n",
    "ds = tfds.load('kmnist', split='test', shuffle_files=True)\n",
    "ds_info = tfds.builder(dataset).info\n",
    "df = tfds.as_dataframe(ds.take(2000), ds_info)\n",
    "new_train_data = np.empty([2000, dim[0], dim[0]])\n",
    "train_data = df['image']\n",
    "for ind, t in enumerate(train_data):\n",
    "    im = Image.fromarray(t.reshape((28,28))).resize((dim[0],dim[0]))\n",
    "    new_train_data[ind] = np.asarray(im)\n",
    "train_data = new_train_data\n",
    "\n",
    "kmnist_digits = np.expand_dims(train_data, -1).astype(\"float32\") / 255\n",
    "\n",
    "encs = vae.encoder.predict(kmnist_digits[0:2000])\n",
    "decs = vae.decoder.predict(encs[0])\n",
    "kmnist_recons = tf.reduce_sum(keras.losses.mean_absolute_error(kmnist_digits[0:2000], decs), axis=(1,2)).numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.fashion_mnist.load_data()\n",
    "fmnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "fmnist_digits = np.expand_dims(fmnist_digits, -1).astype(\"float32\") / 255\n",
    "\n",
    "encs = vae.encoder.predict(fmnist_digits[0:2000])\n",
    "decs = vae.decoder.predict(encs[0])\n",
    "fmnist_recons = tf.reduce_sum(keras.losses.mean_absolute_error(fmnist_digits[0:2000], decs), axis=(1,2)).numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "plt.rcParams.update({\"figure.figsize\": (8,5)})\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "n, bins, patches = plt.hist(fmnist_recons, 25, density=True, facecolor='blue', alpha=0.5, label='Fashion-MNIST')\n",
    "n, bins, patches = plt.hist(mnist_recons, 25, density=True, facecolor='black', alpha=0.5, label='MNIST')\n",
    "n, bins, patches = plt.hist(kmnist_recons, 25, density=True, facecolor='red', alpha=0.5, label='KMNIST')\n",
    "plt.title('Reconstruction error by dataset')\n",
    "plt.xlabel('Reconstruction error')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "plt.savefig('recon_error_by_dataset.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['MNIST', 'KMNIST', 'Fashion-MNIST']\n",
    "threshold = 100\n",
    "\n",
    "hopfield_means = [len([i for i in mnist_recons if i>threshold]), \n",
    "                  len([i for i in kmnist_recons if i>threshold]),\n",
    "                 len([i for i in fmnist_recons if i>threshold])]\n",
    "\n",
    "no_hopfield_means = [len([i for i in mnist_recons if i<threshold]), \n",
    "                  len([i for i in kmnist_recons if i<threshold]),\n",
    "                 len([i for i in fmnist_recons if i<threshold])]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, hopfield_means, width, label='Hopfield encoding required', facecolor='b', alpha=0.5)\n",
    "rects2 = ax.bar(x + width/2, no_hopfield_means, width, label='Hopfield encoding not required', facecolor='r', alpha=0.5)\n",
    "\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Number of memories')\n",
    "ax.set_title('Number of memories stored in Hopfield network by dataset')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 2500])\n",
    "\n",
    "plt.savefig('Hopfield fraction.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
