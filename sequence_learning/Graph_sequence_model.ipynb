{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling sequence learning\n",
    "\n",
    "As in Whittington et al. (2020), we model the spatial task of predicting the next location in a trajectory as the prediction of the next node in a graph. We create a large set of graphs, each one an n-by-n grid of nodes representing a simple spatial environment. Nodes are labelled with random letters to represent arbitrary associations at a particular location. Each directed edge, i.e. each possible transition in the graph, is of the type north, south, east, or west. Random walks in the set of graphs are used to train the model; these could represent sequences stored in an initial bank of memories. The generative model is trained from scratch on the replayed sequences (converted to strings of the form ‘node1 E node2 W node3 …’) with the mechanism of causal language modelling.\n",
    "\n",
    "Tested with conda_pytorch_latest_p36 kernel in AWS SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install simpletransformers csrgraph networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import csrgraph as cg\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "from simpletransformers.language_modeling import (\n",
    "    LanguageModelingModel,\n",
    "    LanguageModelingArgs,\n",
    ")\n",
    "from simpletransformers.language_generation import (\n",
    "    LanguageGenerationModel, \n",
    "    LanguageGenerationArgs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(nodes = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\"]):\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    east_pairs = [(nodes[0], nodes[1]), (nodes[1], nodes[2]), (nodes[3], nodes[4]), \n",
    "                  (nodes[4], nodes[5]), (nodes[6], nodes[7]), (nodes[7], nodes[8])]\n",
    "    south_pairs = [(nodes[0], nodes[3]), (nodes[3], nodes[6]), (nodes[1], nodes[4]), \n",
    "                   (nodes[4], nodes[7]), (nodes[2], nodes[5]), (nodes[5], nodes[8])]\n",
    "    north_pairs = [(i[1], i[0]) for i in south_pairs]\n",
    "    west_pairs = [(i[1], i[0]) for i in east_pairs]\n",
    "\n",
    "    for n in nodes:\n",
    "        G.add_node(n)\n",
    "\n",
    "    for tple in east_pairs:\n",
    "        G.add_edge(tple[0], tple[1], direction='E')\n",
    "    for tple in north_pairs:\n",
    "        G.add_edge(tple[0], tple[1], direction='N')\n",
    "    for tple in west_pairs:\n",
    "        G.add_edge(tple[0], tple[1], direction='W')\n",
    "    for tple in south_pairs:\n",
    "        G.add_edge(tple[0], tple[1], direction='S')\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_G(G):\n",
    "    pos = nx.spring_layout(G, iterations=100, seed=39775)\n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "\n",
    "    nx.draw(G, pos, ax=ax, font_size=8, with_labels=True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#plot_G(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_walks(G):\n",
    "    csr_G = cg.csrgraph(G, threads=12) \n",
    "    node_names = csr_G.names\n",
    "    walks = csr_G.random_walks(walklen=50, # length of the walks\n",
    "                    epochs=10, \n",
    "                    start_nodes=None, \n",
    "                    return_weight=1.,\n",
    "                    neighbor_weight=1.)\n",
    "\n",
    "    walks = np.vectorize(lambda x: node_names[x])(walks)\n",
    "    return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_to_string(walk, G):\n",
    "    walk_string = \"\"\n",
    "    for i in range(len(walk)-1):\n",
    "        node1 = walk[i]\n",
    "        node2 = walk[i+1]\n",
    "        direc = G.edges[(node1, node2)]['direction']\n",
    "        walk_string += str(node1) + \" \"+ str(direc) + \" \"\n",
    "    walk_string += walk[-1]\n",
    "    return walk_string\n",
    "\n",
    "def get_walks_as_strings():\n",
    "    entities_for_graphs =[[random.choice(string.ascii_letters[0:26]) for i in range(9)] for i in range(1000)]\n",
    "    entities_for_graphs = [entities for entities in entities_for_graphs if len(list(set(entities)))== 9]\n",
    "\n",
    "    walks_as_strings = []\n",
    "    for nodes in entities_for_graphs:\n",
    "        G = get_graph(nodes=nodes)\n",
    "        walks = get_random_walks(G)\n",
    "        walks_as_strings.extend([walk_to_string(walk, G) for walk in walks])\n",
    "    return walks_as_strings\n",
    "\n",
    "walks_as_strings = get_walks_as_strings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train generative model\n",
    "\n",
    "Train GPT-2 from scratch on dataset created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "model_args = LanguageModelingArgs()\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.num_train_epochs = 10\n",
    "model_args.dataset_type = \"simple\"\n",
    "model_args.save_model_every_epoch = False\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.mlm = False  # mlm must be False for CLM\n",
    "model_args.learning_rate = 1e-5\n",
    "model_args.vocab_size=100\n",
    "model_args.use_early_stopping = True\n",
    "model_args.manual_seed = 123\n",
    "\n",
    "text_file = open(\"train.txt\", \"w\")\n",
    "walks = get_walks_as_strings()[0:10000]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"test.txt\", \"w\")\n",
    "walks = get_walks_as_strings()[0:1000]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "train_file = \"train.txt\"\n",
    "test_file = \"test.txt\"\n",
    "\n",
    "model = LanguageModelingModel(\n",
    "    \"gpt2\", None, train_files='train.txt', args=model_args\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_file, eval_file=test_file)\n",
    "\n",
    "# Evaluate the model\n",
    "result = model.eval_model(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load trained model for sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageGenerationModel(\"gpt2\", \"outputs\", args={'do_sample': False, 'evaluate_generated_text': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate(\"a E b S e W d N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loops = [\"{} E {} S {} W {} N\", \"{} S {} W {} N {} E\", \"{} W {} N {} E {} S\", \"{} N {} E {} S {} W\",\n",
    "        \"{} E {} N {} W {} S\", \"{} N {} W {} S {} E\", \"{} W {} S {} E {} N\", \"{} S {} E {} N {} W\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop():\n",
    "    random_nodes = [random.choice(string.ascii_letters[0:26]) for i in range(4)]\n",
    "    loop = random.choice(loops)\n",
    "    test_string = loop.format(random_nodes[0], random_nodes[1], random_nodes[2], random_nodes[3])\n",
    "    output = model.generate(test_string)\n",
    "    output = output[0][0:len(test_string)+2]\n",
    "    if output[-1] == output[0]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "results = [test_loop() for i in range(100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what percentage of trials was the next node correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A more challenging test\n",
    "\n",
    "For an arbitrary loop in the graph, can the model predict the final item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cycles_for_graph(G):\n",
    "    cycles = nx.simple_cycles(G)\n",
    "    loops = []\n",
    "    for c in cycles:\n",
    "        path_string = \"\"\n",
    "        for ind, node in enumerate(c):\n",
    "            if ind+1 < len(c):\n",
    "                direction = G.get_edge_data(c[ind], c[ind+1])['direction']\n",
    "                path_string += '{} {} '.format(node, direction)\n",
    "            else:\n",
    "                direction = G.get_edge_data(c[ind], c[0])['direction']\n",
    "                path_string += '{} {} '.format(node, direction)\n",
    "        loops.append(path_string)\n",
    "    return loops\n",
    "\n",
    "def test_loop(num_graphs = 5):\n",
    "    results = []\n",
    "    lens = []\n",
    "    \n",
    "    for i in range(num_graphs):\n",
    "        entities_for_graphs =[[random.choice(string.ascii_letters[0:26]) for i in range(9)] for i in range(100)]\n",
    "        entities_for_graphs = [entities for entities in entities_for_graphs if len(list(set(entities)))== 9]\n",
    "        nodes = entities_for_graphs[0]\n",
    "        G = get_graph(nodes=nodes)\n",
    "        test_strings = get_cycles_for_graph(G)\n",
    "\n",
    "        for test_string in test_strings:\n",
    "            lens.append((len(test_string))/4)\n",
    "            output = model.generate(test_string)\n",
    "            output = output[0][0:len(test_string)+1]\n",
    "            if output[-1] == output[0]:\n",
    "                results.append(1)\n",
    "            else:\n",
    "                results.append(0)\n",
    "    \n",
    "    return results, lens\n",
    "\n",
    "results, lens = test_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot structural inference accuracy against graph cycle length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_for_len(length):\n",
    "    accs = [r for ind, r in enumerate(results) if lens[ind] == length]\n",
    "    return accs.count(1) / len(accs)\n",
    "\n",
    "lengths = [2, 4, 6, 8]\n",
    "accuracies = [acc_for_len(i) for i in lengths]\n",
    "\n",
    "plt.bar(lengths, accuracies, width=1.3, color='skyblue')\n",
    "plt.title('Next node inference accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of transitions')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graph_cycle_length.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.rcParams.update({'font.size' : 15})\n",
    "\n",
    "df = pd.read_csv('outputs/training_progress_scores.csv')\n",
    "df = df.iloc[0:6]\n",
    "df.plot(x='global_step', y='eval_loss', title='Loss over time', \n",
    "                   ylabel='Loss on test set', xlabel = 'Training step', legend=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graph-gpt.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test ability to generate valid graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageGenerationModel(\"gpt2\", \"outputs\", args={'do_sample': True, 'max_length': 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate(\"ia \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt', 'r') as fh:\n",
    "    lines = fh.readlines()\n",
    "    \n",
    "all_train_txt = ' '.join(lines)\n",
    "\n",
    "def test_sequences(seq):\n",
    "    N_num = 0\n",
    "    S_num = 0\n",
    "    E_num = 0\n",
    "    W_num = 0\n",
    "    for ind, char in enumerate(seq):\n",
    "        if char in ['N', 'S', 'E', 'W']:\n",
    "            if char == 'N':\n",
    "                N_num += 1\n",
    "            if char == 'S':\n",
    "                S_num += 1\n",
    "            if char == 'E':\n",
    "                E_num += 1\n",
    "            if char == 'W':\n",
    "                W_num += 1\n",
    "            if N_num == S_num and E_num == W_num:\n",
    "                print(\"Found loop.\")\n",
    "                print(seq[0:ind+3])\n",
    "                if seq[0:ind] in all_train_txt:\n",
    "                    print(\"In training, skipping loop.\")\n",
    "                else:\n",
    "                    if seq[0] == seq[ind+2]:\n",
    "                        print(seq[0], seq[ind+2])\n",
    "                        return 1, ind\n",
    "                    else: \n",
    "                        return 0, ind\n",
    "    return None, ind\n",
    "                \n",
    "def generate_seq():  \n",
    "    rand_letter = random.choice(string.ascii_letters[0:26])\n",
    "    return model.generate(rand_letter)[0]\n",
    "\n",
    "results = [test_sequences(generate_seq()) for i in range(1000)]\n",
    "correct = [i[0] for i in results]\n",
    "lengths = [i[1] for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_for_len(length):\n",
    "    accs = [r for ind, r in enumerate(correct) if lengths[ind] == length]\n",
    "    return accs.count(1) / len(accs)\n",
    "\n",
    "lengths_set = [6, 14, 22, 30]\n",
    "accuracies = [acc_for_len(i) for i in lengths_set]\n",
    "lengths_set = [2, 4, 6, 8]\n",
    "\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size' : 15})\n",
    "\n",
    "plt.bar(lengths_set, accuracies, width=1.3, color='skyblue')\n",
    "plt.title('Correctness of generated graphs')\n",
    "plt.ylabel('Fraction correct')\n",
    "plt.xlabel('Number of transitions')\n",
    "plt.xticks([2, 4, 6, 8])\n",
    "plt.tight_layout()\n",
    "plt.savefig('graph_cycle_length_gen.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
