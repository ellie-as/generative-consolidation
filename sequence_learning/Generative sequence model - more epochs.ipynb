{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methodology:\n",
    "\n",
    "This same mechanism can be applied to other, non language, types of sequence.\n",
    "\n",
    "Here we consider three types of sequence: 1) sequences of arbitrary symbols as in Durrant et al. (2011), in order to model the improved ability to  2) sequences of transitions in a graph as in Whittington et al. (2020), 3) sequences of text - as causal language modelling was originally intended for - in order to explore distortions of memory for narratives increasing over time (as in Bartlett et al.) \n",
    "\n",
    "We create a set of graphs, each one an n by n grid of nodes representing a simple spatial environment. Nodes are labelled with random letters to represent associations at a particular location (as in Whittington et al.). Each directed edge, i.e. each possible transition in the graph, is of the type north, south, east, or west.\n",
    "\n",
    "Random walks in the graph are used to train the model. These represent sequences stored in an initial bank of memories. The generative model is trained on the replayed sequences with the mechanism of causal language modelling, as used to train GPT-2.\n",
    "\n",
    "Causal language modelling\n",
    "\n",
    "GPT-2 learns an explicit density model in which each sequence has a probability, \n",
    "\n",
    "Perplexity is defined as the exponential of the average negative log-likelihood of a sequence, where the average is taken across all tokens. In other words, for each token the log-likelihood of that token given the preceding tokens is found, then these values are averaged. Taking the negative then the exponential of this value gives a positive number that indicates how 'surprising' a sequence is to the model's learned probability distribution.\n",
    "\n",
    "These results show that the original proposal can be extended to sequences, and that one way to do so is the use of autoregressive neural networks, twhich learn to predict the next item in a sequence. Whilst intended for language, these can be adapted for many other types of sequence.\n",
    "\n",
    "We suggest that this could explain the following observations:\n",
    "* \n",
    "*\n",
    "*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install csrgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(nodes = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\"]):\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    east_pairs = [(nodes[0], nodes[1]), (nodes[1], nodes[2]), (nodes[3], nodes[4]), \n",
    "                  (nodes[4], nodes[5]), (nodes[6], nodes[7]), (nodes[7], nodes[8])]\n",
    "    south_pairs = [(nodes[0], nodes[3]), (nodes[3], nodes[6]), (nodes[1], nodes[4]), \n",
    "                   (nodes[4], nodes[7]), (nodes[2], nodes[5]), (nodes[5], nodes[8])]\n",
    "    north_pairs = [(i[1], i[0]) for i in south_pairs]\n",
    "    west_pairs = [(i[1], i[0]) for i in east_pairs]\n",
    "\n",
    "    for n in nodes:\n",
    "        G.add_node(n)\n",
    "\n",
    "    for tple in east_pairs:\n",
    "        G.add_edge(tple[0], tple[1], direction='E')\n",
    "    for tple in north_pairs:\n",
    "        G.add_edge(tple[0], tple[1], direction='N')\n",
    "    for tple in west_pairs:\n",
    "        G.add_edge(tple[0], tple[1], direction='W')\n",
    "    for tple in south_pairs:\n",
    "        G.add_edge(tple[0], tple[1], direction='S')\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "def plot_G(G):\n",
    "    pos = nx.spring_layout(G, iterations=100, seed=39775)\n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "\n",
    "    nx.draw(G, pos, ax=ax, font_size=8, with_labels=True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#plot_G(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csrgraph as cg\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "def get_random_walks(G):\n",
    "    csr_G = cg.csrgraph(G, threads=12) \n",
    "    node_names = csr_G.names\n",
    "    walks = csr_G.random_walks(walklen=50, # length of the walks\n",
    "                    epochs=10, \n",
    "                    start_nodes=None, \n",
    "                    return_weight=1.,\n",
    "                    neighbor_weight=1.)\n",
    "\n",
    "    walks = np.vectorize(lambda x: node_names[x])(walks)\n",
    "    return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_to_string(walk, G):\n",
    "    walk_string = \"\"\n",
    "    for i in range(len(walk)-1):\n",
    "        node1 = walk[i]\n",
    "        node2 = walk[i+1]\n",
    "        direc = G.edges[(node1, node2)]['direction']\n",
    "        walk_string += str(node1) + \" \"+ str(direc) + \" \"\n",
    "    walk_string += walk[-1]\n",
    "    return walk_string\n",
    "\n",
    "def get_walks_as_strings():\n",
    "    entities_for_graphs =[[random.choice(string.ascii_letters[0:26]) for i in range(9)] for i in range(1000)]\n",
    "    entities_for_graphs = [entities for entities in entities_for_graphs if len(list(set(entities)))== 9]\n",
    "\n",
    "    walks_as_strings = []\n",
    "    for nodes in entities_for_graphs:\n",
    "        G = get_graph(nodes=nodes)\n",
    "        walks = get_random_walks(G)\n",
    "        walks_as_strings.extend([walk_to_string(walk, G) for walk in walks])\n",
    "    return walks_as_strings\n",
    "\n",
    "walks_as_strings = get_walks_as_strings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training of None tokenizer complete. Saved to outputs/.\n",
      "file outputs/config.json not found\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training language model from scratch\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b563492d78547d0855893f1c9dcddfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1646de3e070c47f2955c832d67e9625d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_train.txt\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37f289666d54e2e9f38b714367f3e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac6cca9ca4042719146e7f22b26898e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 10:   0%|          | 0/1955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb03edadd644de08bd761010bb01529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0962f70d86c74a4b8fa203bb9622b6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420e8a03374d42e1bc12ae2eccde9e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 10:   0%|          | 0/1955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb7615797d848019e4dd0692ebcea21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95963305b3dc4e2d83f47f8b7c4f76a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Current step: 1\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Early stopping patience: 3\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3260259569614e87bfb0be3e75e8e8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f376753e5d54de4a3ec03b7bca442b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7dd2e4e72c489a8a77bba38ada8af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 10:   0%|          | 0/1955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98cf2072765419781258a2d9b003108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdff3094b63d4239a199f93f282eab8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebeeed2ae38741b28fa70ba6f63ef064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59dc459b945d4a3b9584f6c0f30318bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42092ad9a9b94f7db4a1935aa41c4543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 10:   0%|          | 0/1955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b6b53b10044be082b7db32b54c518e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a686bd7f37dc40a3a9c147af1727f6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Current step: 1\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Early stopping patience: 3\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e81a171a383475b97d9f124199efdb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1032cc39de4bc5be171d763e08ae71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099c989f81b548f9b75a1a58874a8c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 10:   0%|          | 0/1955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77f6f567cc34bda8960d448a0be3097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaeb947d822640f1a834e8e9741cd9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8feed090646d4a23b4b7c3d7a8834b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f0e9fe73bf4fe68b86add71747525d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7fe92632cf42da82d17a67957f8d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 10:   0%|          | 0/1955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f651a3407fc340acb29416a78bb487d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254481cc2f2c46c8ba741ed5144e0cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Current step: 1\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Early stopping patience: 3\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f22bd1ae1c4904a862d99ea6d1f9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfaf2d17322450c8764b73d53ee7793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92be11a8f9cc4488bb90447282488c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 10:   0%|          | 0/1955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49de1d39757a478eb188e40362871c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa0c0d09fdf46e5829c3247b16c945a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec2f42e0fcd48618728516b3c492687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67417b4e0d924d11aa7ded51104ffdc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e0611abdeb48ea90945fb55e7ebecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 10:   0%|          | 0/1955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c9b718312a4fb6a7b4914d7a414dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f55b48f585416887be6ba14b6f180d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Current step: 1\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Early stopping patience: 3\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28190d952d3942d6a7876b1c3d0c0aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9682fba93944001be158d5f225e53cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d433f974c31492d84f25030579c88cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 8 of 10:   0%|          | 0/1955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5148629574b433f893865dd0134b7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09b72335e0e46048b05b3cd29415ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Current step: 1\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Early stopping patience: 3\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e1644a3f334ebb8da7f2255a9f6ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d26749522547d280cce549d5d19e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71aeacd7f485401380411ec53420728e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 9 of 10:   0%|          | 0/1955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125650b125844727b6d58d02944180d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a19c0cf1e145ce877457aabd6aa8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Current step: 2\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Early stopping patience: 3\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3f7039a0b7456fa86902299c9a0f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a010e8628b894c868a1100131c80c519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n",
      "INFO:simpletransformers.language_modeling.language_modeling_model: Training of gpt2 model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Creating features from dataset file at cache_dir/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88780b6992164444bfc417883c59e9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c89246534c41bc830b3bb438662e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_utils: Saving features into cached file cache_dir/gpt2_cached_lm_126_test.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27fddf182fb4abfb516a05c2f5376dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_modeling.language_modeling_model:{'eval_loss': 1.0938143693670934, 'perplexity': tensor(2.9856)}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from random import shuffle\n",
    "\n",
    "from simpletransformers.language_modeling import (\n",
    "    LanguageModelingModel,\n",
    "    LanguageModelingArgs,\n",
    ")\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "model_args = LanguageModelingArgs()\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.num_train_epochs = 10\n",
    "model_args.dataset_type = \"simple\"\n",
    "model_args.save_model_every_epoch = False\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.mlm = False  # mlm must be False for CLM\n",
    "model_args.learning_rate = 1e-6\n",
    "model_args.vocab_size=100\n",
    "model_args.use_early_stopping = True\n",
    "\n",
    "text_file = open(\"train.txt\", \"w\")\n",
    "walks = get_walks_as_strings()[0:10000]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open(\"test.txt\", \"w\")\n",
    "walks = get_walks_as_strings()[0:1000]\n",
    "shuffle(walks)\n",
    "n = text_file.write('\\n'.join(walks))\n",
    "text_file.close()\n",
    "\n",
    "train_file = \"train.txt\"\n",
    "test_file = \"test.txt\"\n",
    "\n",
    "model = LanguageModelingModel(\n",
    "    \"gpt2\", None, train_files='train.txt', args=model_args\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_file, eval_file=test_file)\n",
    "\n",
    "# Evaluate the model\n",
    "result = model.eval_model(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.language_generation import LanguageGenerationModel, LanguageGenerationArgs\n",
    "\n",
    "model = LanguageGenerationModel(\"gpt2\", \"outputs\", args={'do_sample': False, 'evaluate_generated_text': True})\n",
    "#model = LanguageGenerationModel(\"gpt2\", \"outputs\", args={'num_beams': 100, 'num_return_sequences': 5, 'do_sample': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "INFO:simpletransformers.language_generation.language_generation_model:=== GENERATED SEQUENCE 1 ===\n",
      "INFO:simpletransformers.language_generation.language_generation_model:a E b S e W d N e S e N e S e E e W\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a E b S e W d N e S e N e S e E e W']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(\"a E b S e W d N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c E f W\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_generation.language_generation_model:=== GENERATED SEQUENCE 1 ===\n",
      "INFO:simpletransformers.language_generation.language_generation_model:c E f W c E c W c E c W c E\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c E f W c\n",
      "u N h S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_generation.language_generation_model:=== GENERATED SEQUENCE 1 ===\n",
      "INFO:simpletransformers.language_generation.language_generation_model:u N h S h N h S h N h S h N\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u N h S h\n",
      "v W o E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_generation.language_generation_model:=== GENERATED SEQUENCE 1 ===\n",
      "INFO:simpletransformers.language_generation.language_generation_model:v W o E v W o E v W o E v W\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v W o E v\n",
      "j S h N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.language_generation.language_generation_model:=== GENERATED SEQUENCE 1 ===\n",
      "INFO:simpletransformers.language_generation.language_generation_model:j S h N j E j W j E j W j E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j S h N j\n"
     ]
    }
   ],
   "source": [
    "prompts = [\"c E f W\", \"u N h S\", \"v W o E\", \"j S h N\"]\n",
    "for prompt in prompts:\n",
    "    print(prompt)\n",
    "    print(model.generate(prompt)[0][0:len(prompt)+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "INFO:simpletransformers.language_generation.language_generation_model:=== GENERATED SEQUENCE 1 ===\n",
      "INFO:simpletransformers.language_generation.language_generation_model:b E c N f S c N c S c N c S c N\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['b E c N f S c N c S c N c S c N']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(\"b E c N f S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate(\"c E f W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "INFO:simpletransformers.language_generation.language_generation_model:=== GENERATED SEQUENCE 1 ===\n",
      "INFO:simpletransformers.language_generation.language_generation_model:n N q E p S m W n N n S n N n E n W\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['n N q E p S m W n N n S n N n E n W']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(\"n N q E p S m W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "INFO:simpletransformers.language_generation.language_generation_model:=== GENERATED SEQUENCE 1 ===\n",
      "INFO:simpletransformers.language_generation.language_generation_model:n E p S m W v N v E v W v E v W v E\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['n E p S m W v N v E v W v E v W v E']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(\"n E p S m W v N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEOCAYAAAC5GnFMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAt3UlEQVR4nO3dd5wdZb3H8c9vezY92fRks4SEEIJCSCChF5GOKNIkoLTrFb0qFhRBJSqC2NCroCgqqAkoWOhyaYFISQMTSkJJ770n23/3j5lNTjZnd2c355zZc/b7fr3mdXaeeWbmdyYn53fmmWfmMXdHREQkU/LiDkBERDoWJR4REckoJR4REckoJR4REckoJR4REckoJR4REckoJR6RDs7MKszMzWxS3LFIx6DEI7Exs5PCL7yvxh1LrguTyyQzOzzuWEQK4g5ARDKiArgZWAz8p9GyJUAnoDajEUmHpcQjkgPMrBDId/fK1q7rweNLWr2eSFupqU2ygpmdYGZPm9kWM9tlZq+Z2dVJ6o02swfNbIWZVZnZajN73szOTqhTEjY7vWNmO81ss5m9YWY/ihhLZzO7zcwWJOzjj2Y2NKHOqLAZ8adNbON+M6s2sz4JZQPM7FdmtjRcttLMfmNmfRutOync9mgz+6mZLSdIHBOa2NcVwPPh7B/Cdd3MpobL97nGk1hmZheZ2X/C4/6+mV0Z1ik3s4fMbKOZbTOzP5tZ1yT7j/S+pOPQGY+0e2Z2LvAPYDXwE2AbcAlwj5kNc/ebwnq9gefC1X5N0IRUBowDxgOPh8vuBK4C/gjcAeQDI4BTIsRSADwFHAs8FMYzArgWOM3Mxrn7cnefZ2YzgUvN7Hp3r0vYRjfgPOBJd18XlpUDrwBFwO+ABcDwcLsnh9vd0iicycCuMAYHVjUR9ovArcCNwG+AaWH5mpbeL3AO8BngLmAjcDXwezOrDrf5XLjdIwmOaSVwTcJ7bcv7klzn7po0xTIBJxF8YX61mTr5BAlkMzAwobwIeAmoA0aEZR8Jt3dRC/vdCDzRxpj/K9zHDxuVnx2W/ymh7HNh2VmN6l4dlp+fUPYwsBYY3KjuOIJrL5MSyiaF608FClp5rK9IsqwiXDYpSdkOYGhCeR+C5FIPfLnRdv4OVANd2vK+NHWcSU1t0t6NBcqB37v7yoZCd68GfkTQXHxeWNzwy/nM8KyiKVuA0WZ2aBvi+RjBl+5tiYXu/jjBRfvzzKzh/9X9BF/En2y0jU8SJL/HAMysO8GZxSNApZmVNUwEnQHeB05LEsvP3D3dHQL+6e5LGmY8OEN7h+AY3Nmo7jSgkCBp7c/7khynxCPt3QHh61tJlr0Zvg4DcPcXCJrPrgDWm9lLZvYdMzuk0XrXAT2BN8LrNPeYWWLCaCmele6+Kcmyt4CuBM17uPtGgua988IvYcysAjgeuD9MngAjCf4vXg2sSzKNBPol2d+7EeLdXwuTlG0CVrl7VZJygN7ha1vfl+Q4XeOR9s5aU9ndPxV2EjgLOA74CnCTmV3n7r8M6zwcJoCzgBOBUwm+HKeZ2akJCWG/4wHuIzhLuhC4B7g83MYfk2zzz2H9ZHYlKdvZyljaoq6V5bDn/bT1fUmOU+KR9m5B+Do6ybKGM5m9fpW7+5sEZ0M/NLMewHTgB2Z2p3twgSE8G/kz8GczM+AHwNcImu0ebCGeM8ysh7tvThLPVmB9QtkTBL/uP8mexDPf3Wck1Hmf4HpKkbs/08y+90ccIz5m4n1JFlJTm7R3rwFLgSvNrH9DYXjfyvUEX2wPh2W9GjeXhclhEVAKlJhZfpiMEus48Ho426uFeP5J8P/mhsRCMzsTGAM84u71CduuIbjWc5yZXUrQA26vX//uvoEgQZ1vZvt0ibZAn8blrbQ9fG3p/aVMht6XZCGd8Uh78CEzK0lSvt7df21m/0PQnXqmmf2GoDv1xQT3rdzq7u+F9T8JfMnM/kHwa7uGoCntdOCv7r4rTDqrzOwRgmSzluC6zbUE1ygebSHWe4FPAV8Pm+teJOge/FmC7sk3JlnnPuALwK8ILsr/OUmda4F/Ay+a2R/D2PIIrl+dR9A0N6mF2JrzNsFx+6yZ7SToJbjW3Z9rdq39l+73Jdko7m51mjruxJ4uvk1N8xPqngg8TdCUVUnwBXZNo+0dTvAl/z5BN+CtwByC6zzFYZ0igh5pM4ANQBVBD6vfE3bLjhB353AbCwl6ra0F/kRCt+Mk67wRvqenm6lTRtBT793wPW4O1/s5cEhCvUnhtipaebzPIjiDrAzXnxqWV9B0d+pJSbYzFVicpPyKcJ2T2vK+NHWcycIPhoiISEboGo+IiGSUEo+IiGSUEo+IiGSUEo+IiGSUEo+IiGRUh7iPp6yszCsqKuIOQ0QkK8yePXu9u6ft5t4OkXgqKiqYNWtW3GGIiGQFM1vScq22U1ObiIhklBKPiIhklBKPiIhklBKPiIhklBKPiIhklBKPiIhklBJPM3774kJu+NvcuMMQEckpSjzNWL21kn+8voKq2uaGlxcRkdZQ4mnGkRW9qKqt543lW+IORUQkZyjxNOPIip4AzFi8MeZIRERyhxJPM3p3KWbUgG489daauEMREckZSjwtuGjcYOYs28ybK9TcJiKSCko8LTh/zGCKC/KYMmNp3KGIiOQEJZ4WdC8t5NzDBvLw6yvYXlUbdzgiIllPiSeCS8eXs6O6jof/syLuUEREsp4STwRjhvRg1IBuTJm+FHePOxwRkaymxBOBmTFxfDlvrdzKHN3TIyKyX5R4Ijrv8IGUFuUzZXpaB+YTEcl5SjwRdS0p5LzDB/HInJVs2VUTdzgiIllLiacVJo4vp7Kmnn+8tjzuUEREspYSTyscOqg7hw3uzpQZ6mQgItJWSjytdOn4ct5ds51ZSzbFHYqISFZS4mmlcw8bSNfiAqZM15MMRETaQomnlUqLCvjYEYN4/I1VbNpRHXc4IiJZR4mnDS4dX051bT1/UycDEZFWU+Jpg4P7d2Ps0J56koGISBso8bTRxPHlLFy/g1cWbog7FBGRrKLE00ZnfWAAPUoLmaxOBiIiraLE00Ylhfl8/IjBPPXmatZtq4o7HBGRrKHEsx8uHV9Obb3z4OxlcYciIpI1Mp54zGy4md1tZnPMrM7MprZi3fPNbKaZ7TKzDWb2LzPrnMZwm3Vgny5MGNaL+2cspb5enQxERKKI44xnNHAW8G44RWJm1wBTgCeBM4FrgPeAgjTEGNnE8UNZtnEX095fH2cYIiJZI44v7Ufd/WEAM3sIKGtpBTMrA+4APu/uv01Y9I/0hBjd6aP707tzEZNfXcKJB/WJOxwRkXYv42c87l7fhtUuCl/vS2UsqVBUkMeF44bw7Py1rN5SGXc4IiLtXrZ0LhgPvANcbWbLzazGzKab2TFxBwbwiaOGUFfv/GWmOhmIiLQkWxJPf2Ak8E3g68C5wA7gX2bWL87AAIb27szxI8p4YOZSauvackInItJxZEviyQO6AFe7+2R3/xfwUaAO+J9kK5jZp81slpnNWrduXdoDnDi+nFVbKpn6Tvr3JSKSzbIl8WwMX6c2FLj7VmA2cEiyFdz9N+4+zt3H9emT/ov+HxrVj75di5kyQ08yEBFpTqTEY2bPmdnBTSw7yMyeS21Y+5gHOGCNdw+0i7atwvw8LjlyCM+/s5blm3bGHY6ISLsV9YznJKBbE8u6ASekJJqmPUaQZE5uKDCz7sBYYE6a9x3ZxUeVY8ADM9TJQESkKa1patvn1nwzKwJOAVZH3YiZlZrZBWZ2ATAI6NMwb2alYZ33zex3u3fsPgt4GPidmX3KzM4GHgFqgDtb8R7SalCPTpw8si9/mbWMGnUyEBFJqsnEY2Y3h4+0qSNIOq82zCeU7wJuA/7cin32BR4MpwkE12ga5vuGdQqA/EbrXQb8E/gp8BBB0jnF3Te1Yt9pd+n4ctZtq+KZt9fEHYqISLvU3JMLngDWEzRx/S/wE2BxozrVwHx3nxZ1h+6+mH2v1TSuU5GkbDtwbTi1WyeN7MvA7iVMmbGUMz8wIO5wRETanSYTj7vPBGYCmNk24HF31wPJWpCfZ1xyVDk/ffpdFq/fQUVZbM8wFRFplyJd43H3+9x9vZkdYmaXm9mNZtYfdj9tumt6w8wuFx85hPw84/6Z6lotItJY1O7Unc3sr8CbwD3A94CB4eJbgZvTE1526tethFNH9eXBWcupqq2LOxwRkXYlaq+2O4BjgA8BXdn7Gs0TwBkpjivrTRw/lI07qnnqLXUyEBFJFDXxnA983d2fJ3hMTaIlwNCURpUDjhteRnmvUia/uiTuUERE2pWoiacTsKGJZV3ZNxl1eHl5xieOKmf6oo28v3Z73OGIiLQbURPPTOCTTSy7AHg5NeHklgvHDaYw35gyXZ0MREQaRE083wTON7NnCIacduAsM/sTcCHqXJBUWZdiTh/dn4dmL6OyRieFIiIQvTv1vwk6FhQDvyToXPAdYBhwanjPjyQxcfxQtlbW8vjcVXGHIiLSLkR+Vpu7v+TuxxM8FHQw0NXdj3X3l9IWXQ6YMKwXw/p0ZvJ0dTIQEYE2jMfj7rvcfSVQbGaHm1lxGuLKGWbGpUeV89rSzcxbtTXucEREYhf1BtLvmNkPEuZPAZYSDMS20MxGpym+nHDB2MEUFeSpk4GICNHPeCYC8xPmfwL8Gzg2LL8txXHllB6lRZzzgQH84/UV7KiqjTscEZFYRU08A4GFAGY2BDgMuNndXyUYpmBCesLLHZeOL2d7VS2PzlkZdygiIrGKmni2Ad3Dv08BNrn7jHC+EihNdWC5ZuzQnozs15UpM9TcJiIdW9TE8wJwQzjy51cJRgNtcBCgsZ5bYGZMnFDO3OVbmLt8c9zhiIjEJmri+RJQBTwAbAZuSlj2SeDF1IaVmz46ZhCdCvPVyUBEOrSoN5CucPdT3L2rux/v7ol3Q54OfD494eWWbiWFfOSwgTwyZyVbK2viDkdEJBatvo+nMXff6u7VqQimI7h0fDk7q+t4+PUVcYciIhKL/U480jofHNydQwd1Y/L0pbh73OGIiGScEk+GBU8yGMr81dt4benmuMMREck4JZ4YfOTwgXQpLlAnAxHpkJR4YtCluIDzDh/IY3NXsmWnOhmISMcS9VltdWZ2VBPLxpqZBptppYnjh1JVW8/fXlsedygiIhkV9YzHmllWCOgBZK10yMBujCnvweTpS9TJQEQ6lIKmFphZOVCRUDTGzEoaVSsBPgUsSn1oue/So8q5/qG5zFi0kfHDescdjohIRjSZeIArCYa09nD6VRP1dhEMhy2tdM4HB/K9x95m8vSlSjwi0mE0l3juAh4iaGabSzA0wtxGdaqBpe5elZ7wclunonzOP2Iwk6cvYcP2Q+jdRWPqiUjua/Iaj7uvc/e33P1N4ADgoXA+cXpPSWf/TBxfTk2d89BsdTIQkY4haueCUmBsw4yZdTKzW83sn2am57TthxH9unJURS+mzFhKfb06GYhI7ouaeO4Czk2Y/zHwRYLOBbeb2fWpDqwjmTihnCUbdvLygg1xhyIiknZRE8+hwCsAZlYIXAZc5+5nADcCV6UnvI7hjEP707O0kMnTl8QdiohI2kVNPJ2BreHfE8L5v4fzrwFDUxxXh1JckM+F44bw9NtrWLu1Mu5wRETSKmriWUiQcAA+Brzu7g3tQmUEQ2PLfvjEUeXU1jt/naXBXEUkt0VNPHcAt5jZTOALwP8mLDuJfbtZSysdUNaZY4f35v4Zy6hTJwMRyWFRRyD9HXAqwdDXp7v7nxIWbwR+lvrQOp6J44eyYvMuXnx3XdyhiIikTXM3kO7F3V8EXkxSPimVAXVkHz6kH2Vdipk8fSknH9w37nBERNIi8rAIZtbXzG43s2fN7F0zGx2Wf9HMjk5fiB1HYX4eFx85mOfmr2Hl5l1xhyMikhZRh0U4Cngf+DiwGDgQaHi+ywDgK+kIriO65MhyHHhgpjoZiEhuak3ngueAg4D/Zu9hEmYAScfqkdYb0quUEw/qw19mLqW2rj7ucEREUi5q4jkCuMvd6wmeVJ1oA6ALEil06VHlrNlaxbPz18YdiohIykVNPFuAPk0sGwasSU04AnDKwX3p362EKdOXxh2KiEjKRU08DwPfMbNhCWVuZmXAV9nzFANJgYL8PC4+cggvvreOZRt3xh2OiEhKRU08NxA8Mudt9nSp/jXwDsFAcN9OfWgd2yVHDcGA+2forEdEckvUG0g3ETwy53PAEuAZguGubwCOdXc9MifFBnTvxCkH9+Ovs5ZRXatOBiKSO1pzA2k18LtwkgyYOKGcZ+at4em313D2BwfEHY6ISEpEvY+nLryXJ9mysWZWl9qwBOCEEX0Y3LOThksQkZwS9RqPNbOsEKhNQSzSSH6e8Ymjynl5wQYWrtsedzgiIinRZOIxs3IzO8HMTgiLxjTMJ0ynAZ8nuN4jaXDhuMHk5xn/fH1F3KGIiKREc9d4rgRuJrhh1IFfNVFvF3BNiuOSUN+uJZT3KmXBuh1xhyIikhLNJZ67gIcImtnmAhPZd9ydamCpu1elJzwBGNyzE8v10FARyRFNJh53XwesAzCzA4BVYc82ybDBPTvx9Nt6OISI5Iao9/EsSVXSMbPhZna3mc0Je8tNbeX6eWY228zczM5JRUzt3eCepazfXs2uanUeFJHsF3k8nhQaDZwFvBtOrXUNMCilEbVzg3t2AmDFZj0+R0SyXxyJ51F3H+LuFwJvtWZFM+sJfB+4KS2RtVMNiWfZJl3nEZHsl/HEEw6t0FbfA14Cnk1ROFlhcM9SAJYr8YhIDoj8yJy4mdkHCbp4HxZ3LJnWp0sxRfl5LN+kpjYRyX6RE4+ZlQAnAIOBkkaL3d2bus8nVX4B3Onu75tZRZr31a7k5RmDenbSGY+I5IRIicfMjiMYc6esiSrN3WC638zsEmAkcG4r1vk08GmA8vLyNEWWOYOVeEQkR0S9xvO/wAJgDFDs7nmNpvx0BWhmhcCPgNuBPDPrAXQLF3c2s67J1nP337j7OHcf16dPU4OnZo/BPTuxQk1tIpIDoiaekcAkd5/j7jXpDCiJzgTNez8FNoXTnHDZA8DrGY4nFg338uys1vNYRSS7Rb3GMxfon85AmrEdOLlRWX/gfuBG4LmMRxSDI8p7AjBl+lKuOX5YC7VFRNqvqInnWuBeM1vs7i/szw7NrJTgBlIIbgTtZmYXhPNPuPtOM3sfeMHdr3b3WmBqo21UhH++4e7T9yeebHH0gb058aA+/PzZ9zj/iMH06lwUd0giIm0StantaWAE8JyZVZrZ2sZTK/bZF3gwnCYAhyTM9w3rFABpu26Urb559ih2Vtfx82fa8sAHEZH2IeoZz50EPdf2m7svpvmB5XD3iv3dRi4a0a8rnzhqCH+evpTLjx7K8L5J+1WIiLRrkRKPu09KcxwS0ZdOPYiHX1/JrU/M5/dXHBl3OCIirdaqR+aYWZGZjTWzD4evutCQYb27FPM/pwznuflrmfbeurjDERFptciJx8y+BqwBZgBPATOBNWZ2fZpikyZccWwFQ3p14pbH5lFXn5IWUBGRjImUeMzsOuA2YApB1+ZRwEnh/G1m9oU0xSdJFBfk840zR/HOmm38ZeayuMMREWmVqJ0LPgf8wN0ThyN4B3jRzDYDXyB4uoFkyJmH9ufIip789Ol3OPewAXQtKYw7JBGRSKI2tQ0Bnm9i2VSCJwtIBpkZ3zz7ENZvr+auqQviDkdEJLKoiWcpcFoTyz4cLpcMO2xID84fM4jf/XsRyzbqOW4ikh1a85DQr5rZPWZ2hpmNMbPTzewe4MvAz9IWoTTr+jNGkmdw+7/mxx2KiEgkkRKPu/8S+G/gDOAJYBbwZDj/GXe/K20RSrMGdO/Ep084kMfmrmL2ko1xhyMi0qLI3and/bcE13qGAkeHr0Pc/Z40xSYRfebEYfTtWsx3H5tHvbpXi0g716obSD2wzN1nhK/6lmsHSosKuP70kcxZtplH566MOxwRkWa1KvFI+/XxIwZz6KBu3P7kfCpr6uIOR0SkSUo8OSIvL+hevXJLJfdMWxh3OCIiTVLiySEThvXm9NH9uGvqAtZuq4w7HBGRpJR4csw3zhxFTV09P3lKY/aISPvU5sRjZgeb2UfNbGAqA5L9U1HWmU8dXcFfZy/jrZVb4g5HRGQfUR8SereZ/Tph/mLgDeDvwHwzOyZN8UkbfP5DI+jRqZDvPz4PdTwUkfYm6hnPGcCLCfPfA+4HBhIMkfC9FMcl+6F7p0KuO/UgXl6wgWfmtWZUchGR9IuaePoCywDMbAQwHPihu68GfgOMSU940laXji/nwD6dufWJeVTX1scdjojIblETz0agX/j3qcBqd38znDcgP9WByf4pzM/jprNHsWj9Dv786pK4wxER2S1q4nkS+K6ZfQ64AfhrwrJDgcUpjktS4OSRfTl+RBk/f/Y9Nu+sjjscEREgeuL5CvAq8BmCaz3fTlj2MeBfKY5LUsDMuOnsUWyrrOHnz74XdzgiIkDEEUjdfQtwVRPLjk9pRJJSB/fvxsVHlvOnV5Zw+YShDOvTJe6QRKSDi9qdusDMihuVnWZm15mZOha0c1/+8EGUFOZz6xMas0dE4he1qe0vwK8aZszsCwTNa7cB083snDTEJinSp2sxnz35QJ6Zt4aX318fdzgi0sFFTTwTCAaAa3A98BN37wTcA9yU6sAkta469gAG9ejE9x6fR53G7BGRGEVNPL2B1QBm9gGCG0cbnmTwIHBI6kOTVCopzOeGMw9m3qqtPDR7WdzhiEgHFjXxrAEqwr/PAJa4+4JwvhOgOxSzwDkfHMAR5T348f+9y/aq2rjDEZEOKmrieRC43cx+BHwd+GPCsjGA+upmATPjW+ccwrptVfx66oKWVxARSYOoiecG4G7gYIJOBrclLBtL0PlAssCY8p6cd/hAfjttISs274o7HBHpgCIlHnevdffvuvu57v4td69KWHa+u/8kfSFKqn3tjIMB+OG/1L1aRDKvVePxmNl4M/uKmX0/fB2frsAkfQb16MR/HT+Mh/+zkteXboo7HBHpYKLeQNrZzJ4AXiFoZrsqfH3ZzB43s9I0xihpcO1JB9KnazG3aMweEcmwqGc8PwSOBi4GStx9AFACXBKW356e8CRdOhcX8NXTDmL2kk08/saquMMRkQ4kauL5OPB1d3/Q3esB3L3e3R8k6HhwYboClPS5YOwQRg3oxg+enE9lTV3c4YhIBxE18XQnHAguiWVAt9SEI5mUn2d86+xRLN+0i9+/tCjucESkg4iaeOYA15qZJRaG89eGyyULHTO8jFNH9eOu5xewbltVyyuIiOynqInnRuB0YL6Z/cDMvmRmtwHzwvIb0xWgpN+NZx1MZU0dP3363bhDEZEOIOp9PM8RPKHgdYLrOd8HLgJeA8a4+/Npi1DSblifLlx+9FD+MnMp81dvjTscEclxke/jcfe33f0Sdz/Q3UvD10uBNWZ2QhpjlAz44odG0LWkkO+re7WIpFmrbiBtwkmAzniyXI/SIr74oRFMe289U99ZF3c4IpLDUpF4JEdcfvRQhpV15pbH36amTg8cF5H0UOKR3Qrz8/jGWaNYsG4H989YGnc4IpKjlHhkL6eO6ssxB/bmjqffZcvOmrjDEZEcpMQjezEzbjp7FJt31fCL5zTMkoikXkFTC8xsHRCle1Nx6sKR9mD0wO5cNHYI972ymMsmDKWirHPcIYlIDmky8QB3Ei3xSA76ymkH8ejcldz25Dzuvnxc3OGISA5pMvG4+6QMxiHtTN9uJXz2pAP58f+9y6sLNzBhWO+4QxKRHKFrPNKka44fxsDuJdzy+NvU1+vkV0RSQ4lHmlRSmM/XzzyYN1ds5e+vr4g7HBHJEUo80qyPHDaQw4f04EdPzWdndW3c4YhIDsh44jGz4WZ2t5nNMbM6M5saYZ0jzewPZva+me00s3fM7GYzK8lAyB2amfGtc0axZmsVd7+wMO5wRCQHxHHGMxo4C3g3nKK4GDiQYIjtswh63H0ZmJyOAGVvY4f24pwPDuDuFxewbOPOuMMRkSwXR+J51N2HuPuFwFsR17nd3U9w99+6+1R3/1/geuB8MxuavlClwQ1nHkxhfh6f/tNsdlVrmGwRabuMJx53b/XTJ9092eOSXw9f++5fRBLF4J6l/OITY5i/eitf+9tcDZ0gIm2WzZ0LjgHqgXfiDqSjOGlkX752+sE8OmclX3zgPxo0TkTapLknF7RbZtYfuAn4k7vr2y+DPnPiMLZV1vCHlxbzyJyVHD+ijKuOO4ATR/QhL8/iDk9EsoDF2WRiZg8BZe5+UivWKQKeAQYDY919UxP1Pg18GqC8vHzskiVL9j9g2W3zzmrun7GMe19exJqtVQzv24WrjzuAj40ZRElhftzhich+MLPZ7p62Z2VlVeIxMwPuBz4MHOvu86OsN27cOJ81a1ab45SmVdfW88Qbq/jttIW8tXIrvToXcdmEoVw+YSh9uur5sSLZKN2JJ9ua2u4AzgM+HDXpSHoVFeTx0TGDOO/wgUxftJF7pi3iF8+9x6+nLuCjYwZy9XHDGNm/a9xhikg7kjWJx8y+AXweuMjd/x13PLI3M2PCsN5MGNabheu284eXFvPg7GX8ddZyjh9RxjXHD+OEEWUEJ60i0pFlvKnNzEoJbgIF+ArQDbg5nH/C3Xea2fvAC+5+dbjOpQQ3i94L3N1okwua6G69m5ra4rFpRzVTZizlvpcXs3ZbFQf1C64DnXe4rgOJtGc5d43HzCqARU0sPsDdF5vZYmCqu18RrnMv8Kkm1rnS3e9tbp9KPPGqrq3nsbkr+e20RcxbtZXenYu4/OihXDZhKGVddB1IpL3JucQTByWe9sHdeWXhBn43bRHPzl9LUUEe548ZxFXHHcBB/XQdSKS9UOcCyRlmxjEHlnHMgWW8v3Y7f3hpEQ/NXs4DM5dx4kF9uPq4Azhe14FEcp7OeCRWG3dUM2X6Eu57ZQnrtlUxsl9Xrj7uAD5y+EBdBxKJiZraUkCJp/2rqq3j0TmruGfaQuav3kZZlyIun1DBZRPK6a3rQCIZpcSTAko82cPdeXnBBu6ZtpDn31lHcUEe5x8xiKuPO4DhfXUdSCQTdI1HOhQz49jhZRw7vIz3127jd/9ezN9fW879M5Zx0sg+XHPcMI4d3lvXgUSymM54pN3bsL2KydOX8sdXFrN+ezUH9unMmYcO4LTR/fjAoO5KQiIppqa2FFDiyQ2VNXU8Mmcl/3htBTMWb6Su3unVuYjBPTvRv1sJ/bsH04DuJfTrVsKA7kF5pyJ1UhBpDTW1iYRKCvO5aNwQLho3hE07qnl2/lpmLd7Iqi2VLN24k+mLNrJlV80+6/UoLdydmPYkpRL6d9+TsLqVFOjMSSRDlHgkK/XsXMQFYwdzwdjBe5XvrK5l9ZZKVm+tZPWWSlZtqWTN1uB19ZZK3lyxlQ07qmh8ol9alL/PWVMw32l3surduajJMYcqa+owg+ICnV2JtESJR3JKaVEBw/p0YVifLk3Wqa6tZ+22yn0SVMP89IUbWbO1ktr6vbNTYb7Rr1uQkPp1L6Gqpp6Vm3excssuNu8MzrSKCvLoWlxA15ICupQU0KW4gK4lhY3KCulaUrB76lJcGNZrmC+gID+bBwcWaZ4Sj3Q4RQV5DO5ZyuCepU3Wqat3NmyvYvXWvZNSkKR28daKLZQU5jOgewljynswoHsJANsqa9lWVcv2ylq2VdawvaqWZRt3sq2ylu1VQVl9hMuqnQrz6dKQnMLk1aW4YJ+yzsUFlBblU1KYT6eifEoK8iguzKcgz8hPmAryjDwzCvLDMjMK8vLIzw/+3l1nP0aRdXe2VtaycvMuVm3ZxaotlVTV1OPhsj31wPHwde/5hu00LEtWH/d91muoW5BnlBTmU1yQt9drYb5R78G/a72HUz3UuePu1NWTUO7UOWG5U+8klIfz4Xbqwlh3bzesU1vn1NQ5NXX11NbXU1275++mGPse+9a0/iZrKr7z0jF0LSmMvpEMUeIRSSI/z+jbrYS+3Ur44OCW60fl7uyqqWN7ZS1bE5LR9jBhbavcO2ntKath7bbK3cu3V9fu01yYKg0JqKBR4mpIWPn5QdLKM4LklWdU19WzavMudlTXpSeoRszACL5sbfe8UVNfn7bjkijPgs+IWXBM8gzywuTecLwK8/MozA9eC/LzKMo3CvLzkqSXPYlzr7Im3kjyusnjbK9dx5R4RDLIzCgtKqC0qIC+3dq+nfp6Z0d1kLh2Vdexq6aOypp6KmvqqKqto64e6urrqa0PfrXX1Tu19cEv8sSy3eXhr/S6+vrgF3tzdRuV19Y7BXnG8SPKGNSjEwO6d2Jgj6BXYUlhXvBL3vb8ek+WMHYvS5hvqLdnneS/6hO5O9V19VTW1FNVU0dVbXBMauqc/LxGCcKC/eSH83l57C7faz4vrLe7XJ1Q9pcSj0gWysuz4NpRO2xGiZOZUVyQH3Ty6KRj017pCqaIiGSUEo+IiGSUEo+IiGSUEo+IiGSUEo+IiGSUEo+IiGSUEo+IiGRUhxgWwczWAUvijqMdKQPWxx1EDtJxTQ8d1/Ro7rgOdfc+6dpxh0g8sjczm5XOsTY6Kh3X9NBxTY84j6ua2kREJKOUeEREJKOUeDqm38QdQI7ScU0PHdf0iO246hqPiIhklM54REQko5R4soiZXWFmnmT6TEIdM7MbzWyZme0ysxfN7PAk2zrEzJ41s51mttLMvmtm+Y3qRNpWtjGz4WZ2t5nNMbM6M5uapE7Gj2OUbbVnEY/r4iSf39VJ6um4AmZ2oZk9YmYrzGy7mc02s080qpN9n1UPh37V1P4n4AqCQQVPBiYkTH0T6nwD2AX8D3Aq8ARBX/3+CXV6AiuBZ4APA58BdgC3NNpfi9vKxgk4D1gGPAjMA6YmqZPR4xh1W+15inhcFwOTG31+j2hUR8d1T/yvAFOAi4BTgB+H3wGfz+bPauwHVlOrPoRXhB+6Lk0sLwG2AN9OKOsMrEv8UIQfrk1At4SyrwE7G8qibisbJyAv4e+HGn9BxnEco2yrvU8tHdewfDHw4xa2o+O6J9ayJGVTgEXZ/FlVU1tuOQboBvy1ocDddwCPAmcm1DsTeMrdtyaUPQB0Ak5s5bayjrvXt1AljuMYZVvtWoTjGpWOa8jdkz1Z4HWgb/h3Vn5WlXiy0wIzqzWzd8zsvxPKDwbqgPca1Z8XLkusNz+xgrsvJfjFcnBCnSjbykVxHMco28oVV5lZtZltMbOHzGxoo+U6rs07Bng7/DsrP6sFUSpJu7EK+BYwA8gHPgH82sxK3f0OgrbX7e5e12i9TUCpmRW5e3VYb3OS7W8Kl9GKbeWiOI5jlG3lgoeBV4HlwCjgZmCamX3A3beEdXRcm2BmHyK4lnZVWJSVn1Ulnizi7k8BTyUUPWlmxcA3zeznDdWSrGpJljVVL0qdppblkjiOY5RtZTV3/2LC7DQzexn4D3Al8LPEqklW79DH1cwqCK7vPOzu9yYsyrrPqprast9DQC+gguAXR9ck3Rp7ADvdvSac3xSWNdadPb9kom4rF8VxHKNsK+e4+5vAO8ARCcU6ro2YWS/gSWApcFnCoqz8rCrx5A4naHfNB4Y3Wta4TXY+jdpizWwIQQ+W+Ql1omwrF8VxHKNsK5cl/lLWcU1gZqXAY0ARcHZ4wb9BVn5WlXiy38cJ+tkvAV4GtgIXNiwMP7TnEvxaavAkcLqZdU0ou5ig//4L4XzUbeWiOI5jlG3lHDM7FBgJzE4o1nENmVkBwX1RI4Az3X1toyrZ+VmNu5+6plb16f8b8HWC7oznAH8i+c1kO4HPAR8CHidITP0S6vQk6KjwNMFNYp8GtpP8ZrJmt5WNE1AKXBBOrwBvJcyXxnEco26rPU8tHVfgbOB+YCLBTdDXAiuAhex9T4iO6574fxP+H/8Ce990OwEoztbPauwHVlOrPoS3ErSH7yT4dTEbuLxRHQNuIug1tAuYBoxJsq1DgOfCOquA7wH5bdlWtk0E18O8iakiruMYZVvteWrpuAIfBJ4luCGxBlgN3AsM1HFt8pguzsXPqp5OLSIiGaVrPCIiklFKPCIiklFKPCIiklFKPCIiklFKPCIiklFKPCIiklFKPJK1kgyhnGw6qY3brgjXP6eV650UrndoW/abambW18wmhQ+YFGkXdB+PZC0zm5Aw24nghrZbCO62bvC27z1gVdRtFwNjgPnuvrkV63UjuLlujrvvau1+Uy1MgG8AJ7v71JjDEQE0LIJkMXd/teFvM+sS/rkgsTxR+NTdfI8wjpC7VxGMG9PamLa2ZT2RjkRNbZKzzOxeM5tlZh81s7eASmC8mQ0ws9+b2UIz22Vm75rZLWZWlLDuPk1tZrbYzH5sZl8ys+VmtsnMHjCzHgl19mlqC+e/aGa3mtk6M1trZneGZ1U0WneumVWa2UwzO8rM1pvZpBbe59Vm9lb4Xtab2QtmNjpsXnsjrPZ8Q/Njwnq9zOxuM1sT7vNlMxvfaNtuZl82s5+b2UYz22xmv0g8ViKtpTMeyXUVwA+B7wJrgEVAGbAR+DLB2CIHAZOAPsB/J9tIgouAuQQPRhwM/JTgGXqfbWG9rxA0BV5G8Myy2wieKP5DADMbBDxB8ITgG4H+wGSCJsQmmdkJwK+BbxM8mLMbcDTB2CjvEzyQczLBQx9fS1ivGHiGYFyV64G1BA/tfMbMRrj76kaxvxpuazTwfYIkfn0L71kkKSUeyXW9gVPd/T8JZcuBrzbMmNlLwA7g92b2+Raa4mqAj7p7bbjuIcAltJx4Frv7FeHfT5nZscD5hIkHuI7g4a/nNlwbMrOtwF9a2O5RwFx3vy2h7JGE9zY3/PPtRk2QlwGHAqPd/b2w7jMED6H9CnsnlW3Ahe5ez55Rb28ys9vcfWML8YnsQ01tkutWNEo6WOA6M3vbzHYRJJPJQDFQ3sL2nm9IOqG3gb4Rmp7+r9H82wRnTA2OBJ5u1CHhEVr2H2CMmd1hZie0ognsVIKnmy8ys4Jw3BcIxlMZ16juw2HSafB3gjOxdtFzT7KPEo/kujVJyq4DfgL8AziP4Kzhc+Gykha2t7nRfDXBo+Rb+sJPtl7ivvoTDBewm7tXEoxz0iR3fwa4EjgBmAqsN7O7zKxzC/GUEYzpUtNouhIY0qhu48HHGuYHtLAPkaTU1Ca5Ltn9AhcCD7r7TQ0FYZNZnFYTXGPazcxKgC7Jq+/h7vcB95lZH4LmuzsIRpK8oZnVNgKzCK7rNFbVaL5vE/OrWopNJBklHumIOrHvl+vEOAJJMBO40sw6JTS3faQ1G3D3dcDdZnY+wb1EEJxZwb5ncs8CpwFLfd/hlBs7z8y+kdDcdj7BAGBvtiY+kQZKPNIRPQ18wcymAwsIks7weEPiZwTNfY+a2R0ETW83EHQ4qG9qJTP7DtCLsJmN4KbXE9lztrOUIEl8ysy2ADXuPgv4I/AZYKqZ/Zhg+OneBM2Oq939joTddAUeNLPfEvRq+zbwS3UskLZS4pGO6LsEzVq3hPN/JxjT/tG4AnL3FWZ2NvDzMJ55wFUESbK5Jy/MBL5E0LOuK0EX7UnhdnD3SjP7L+Bmgo4DhQRPLKk0s5MJjsV3gH4E125msG+nhp8Aw4D7Ca4L30PQ5VukTfTIHJF2ysyOIxjz/hR3fz6mGBz4vLv/Mo79S27SGY9IO2FmtwOvE3Q0GAl8i+Bm1RfijEsk1ZR4RNqPYuBHBM1e2wju/flyo3toRLKemtpERCSjdAOpiIhklBKPiIhklBKPiIhklBKPiIhklBKPiIhklBKPiIhk1P8DslF6AMcSKpgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.rcParams.update({'font.size' : 15})\n",
    "\n",
    "#df = pd.read_csv('outputs_best_so_far/training_progress_scores.csv')\n",
    "#df.at[0,'eval_loss'] = 1.91\n",
    "#df.at[0,'eval_loss'] = 1.51\n",
    "df.plot(x='global_step', y='eval_loss', title='Loss over time', \n",
    "                   ylabel='Loss on test set', xlabel = 'Training step', legend=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graph-gpt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[0,'eval_loss'] = 1.69\n",
    "df.at[1,'eval_loss'] = 1.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_step</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1955</td>\n",
       "      <td>tensor(4.9275)</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>1.580271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>tensor(4.8995)</td>\n",
       "      <td>1.680000</td>\n",
       "      <td>1.548511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3910</td>\n",
       "      <td>tensor(4.1714)</td>\n",
       "      <td>1.428263</td>\n",
       "      <td>1.286327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4000</td>\n",
       "      <td>tensor(4.0140)</td>\n",
       "      <td>1.389796</td>\n",
       "      <td>1.332442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5865</td>\n",
       "      <td>tensor(3.3660)</td>\n",
       "      <td>1.213714</td>\n",
       "      <td>1.248935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6000</td>\n",
       "      <td>tensor(3.3360)</td>\n",
       "      <td>1.204765</td>\n",
       "      <td>1.155488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7820</td>\n",
       "      <td>tensor(3.1950)</td>\n",
       "      <td>1.161574</td>\n",
       "      <td>1.150539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8000</td>\n",
       "      <td>tensor(3.1854)</td>\n",
       "      <td>1.158575</td>\n",
       "      <td>1.116949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9775</td>\n",
       "      <td>tensor(3.1529)</td>\n",
       "      <td>1.148327</td>\n",
       "      <td>1.065105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000</td>\n",
       "      <td>tensor(3.1574)</td>\n",
       "      <td>1.149734</td>\n",
       "      <td>1.092129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11730</td>\n",
       "      <td>tensor(3.1410)</td>\n",
       "      <td>1.144550</td>\n",
       "      <td>1.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12000</td>\n",
       "      <td>tensor(3.1393)</td>\n",
       "      <td>1.144011</td>\n",
       "      <td>1.052333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13685</td>\n",
       "      <td>tensor(3.1353)</td>\n",
       "      <td>1.142721</td>\n",
       "      <td>1.014591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14000</td>\n",
       "      <td>tensor(3.1414)</td>\n",
       "      <td>1.144665</td>\n",
       "      <td>1.051636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15640</td>\n",
       "      <td>tensor(3.1424)</td>\n",
       "      <td>1.144989</td>\n",
       "      <td>1.097708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16000</td>\n",
       "      <td>tensor(3.1403)</td>\n",
       "      <td>1.144315</td>\n",
       "      <td>1.024781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17595</td>\n",
       "      <td>tensor(3.1429)</td>\n",
       "      <td>1.145150</td>\n",
       "      <td>1.017324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18000</td>\n",
       "      <td>tensor(3.1444)</td>\n",
       "      <td>1.145630</td>\n",
       "      <td>1.048560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19550</td>\n",
       "      <td>tensor(3.1442)</td>\n",
       "      <td>1.145568</td>\n",
       "      <td>1.032417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    global_step      perplexity  eval_loss  train_loss\n",
       "0          1955  tensor(4.9275)   1.690000    1.580271\n",
       "1          2000  tensor(4.8995)   1.680000    1.548511\n",
       "2          3910  tensor(4.1714)   1.428263    1.286327\n",
       "3          4000  tensor(4.0140)   1.389796    1.332442\n",
       "4          5865  tensor(3.3660)   1.213714    1.248935\n",
       "5          6000  tensor(3.3360)   1.204765    1.155488\n",
       "6          7820  tensor(3.1950)   1.161574    1.150539\n",
       "7          8000  tensor(3.1854)   1.158575    1.116949\n",
       "8          9775  tensor(3.1529)   1.148327    1.065105\n",
       "9         10000  tensor(3.1574)   1.149734    1.092129\n",
       "10        11730  tensor(3.1410)   1.144550    1.051600\n",
       "11        12000  tensor(3.1393)   1.144011    1.052333\n",
       "12        13685  tensor(3.1353)   1.142721    1.014591\n",
       "13        14000  tensor(3.1414)   1.144665    1.051636\n",
       "14        15640  tensor(3.1424)   1.144989    1.097708\n",
       "15        16000  tensor(3.1403)   1.144315    1.024781\n",
       "16        17595  tensor(3.1429)   1.145150    1.017324\n",
       "17        18000  tensor(3.1444)   1.145630    1.048560\n",
       "18        19550  tensor(3.1442)   1.145568    1.032417"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
