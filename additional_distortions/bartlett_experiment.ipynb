{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bartlett experiment with GPT-2\n",
    "\n",
    "* This notebook fine-tunes GPT-2 on the story from the Bartlett experiment (1932) plus contextual data, in order to explore how generative models produce distortions\n",
    "* This context is taken from the cnn_dailymail dataset of news article content (see https://www.tensorflow.org/datasets/catalog/cnn_dailymail for further details)\n",
    "* We then explore recall of Bartlett story - can substitutions and confabulations be observed in generative recall?\n",
    "* How does temperature parameter for sampling explore level of distortion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install simpletransformers\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow_datasets\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import tensorflow_datasets as tfds\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from simpletransformers.language_modeling import (\n",
    "    LanguageModelingModel,\n",
    "    LanguageModelingArgs,\n",
    ")\n",
    "from simpletransformers.language_generation import LanguageGenerationModel, LanguageGenerationArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load('cnn_dailymail', split='train')\n",
    "\n",
    "articles = []\n",
    "for example in ds: \n",
    "    articles.append(example[\"article\"].numpy().decode(\"utf-8\"))\n",
    "    \n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bartlett = [\"One night two young men from Egulac went down to the river to hunt seals and while they were there it became foggy and calm.\", \n",
    "            \"Then they heard war-cries, and they thought: 'Maybe this is a war-party'.\",\n",
    "            \"They escaped to the shore, and hid behind a log.\",\n",
    "            \"Now canoes came up, and they heard the noise of paddles, and saw one canoe coming up to them.\",\n",
    "            \"There were five men in the canoe, and they said:\"\n",
    "            \"What do you think? We wish to take you along. We are going up the river to make war on the people.\",\n",
    "            \"One of the young men said,'I have no arrows.'\",\n",
    "            \"'Arrows are in the canoe,'' they said.\",\n",
    "            \"'I will not go along. I might be killed. My relatives do not know where I have gone. But you,' he said, turning to the other, 'may go with them.'\",\n",
    "            \"So one of the young men went, but the other returned home.\",\n",
    "            \"And the warriors went on up the river to a town on the other side of Kalama.\"\n",
    "            \"The people came down to the water and they began to fight, and many were killed.\"\n",
    "            \"But presently the young man heard one of the warriors say, 'Quick, let us go home: that man has been hit.'\", \n",
    "            \"Now he thought: 'Oh, they are ghosts.' He did not feel sick, but they said he had been shot.\",\n",
    "            \"So the canoes went back to Egulac and the young man went ashore to his house and made a fire.\",\n",
    "            \"And he told everybody and said: 'Behold I accompanied the ghosts, and we went to fight. Many of our fellows were killed, and many of those who attacked us were killed. They said I was hit, and I did not feel sick.'\",\n",
    "            \"He told it all, and then he became quiet. When the sun rose he fell down.\", \n",
    "            \"Something black came out of his mouth. His face became contorted. The people jumped up and cried. He was dead.\"\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_list = []\n",
    "\n",
    "for a in articles:\n",
    "    sents = a.split('. ')\n",
    "    sents_list.extend([s for s in sents if len(s) >100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [s for s in sents_list if 'kill' in s][0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_list = filtered[0:100] + bartlett\n",
    "sents_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train.txt', 'w') as fh:\n",
    "    fh.write('\\n'.join(sents_list))\n",
    "    \n",
    "with open('data/test.txt', 'w') as fh:\n",
    "    fh.write('\\n'.join(sents_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "model_args = LanguageModelingArgs()\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.num_train_epochs = 400\n",
    "model_args.dataset_type = \"simple\"\n",
    "model_args.mlm = False\n",
    "model_args.fp16=False\n",
    "model_args.save_model_every_epoch = False\n",
    "model_args.save_best_model = True\n",
    "\n",
    "train_file = \"data/train.txt\"\n",
    "test_file = \"data/test.txt\"\n",
    "\n",
    "model = LanguageModelingModel(\n",
    "    \"gpt2\", \"gpt2\", args=model_args, use_cuda=True, train_files=train_file, \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_file, eval_file=test_file)\n",
    "\n",
    "# Evaluate the model\n",
    "result = model.eval_model(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore recall of story using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_params(temperature=1.0):\n",
    "    model_args = LanguageGenerationArgs()\n",
    "    model_args.temperature = temperature\n",
    "    model_args.do_sampling= True\n",
    "    model_args.max_length = 500\n",
    "    model_args.num_beams = 1\n",
    "    model_args.repetition_penalty = 1.05\n",
    "    model_args.top_k = 50\n",
    "\n",
    "    model = LanguageGenerationModel(\"gpt2\", \"./outputs_set_1/\", args=model_args)\n",
    "    \n",
    "    return model.generate(bartlett[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = {}\n",
    "generated['set_1'] = {}\n",
    "\n",
    "for i in [0.1,0.5,1.0,1.5,2.0]:\n",
    "    gen_list = []\n",
    "    for n in range(4):\n",
    "        gen_list.append(generate_with_params(temperature=i))\n",
    "    generated['set_1'][i] = gen_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated['set_1'][1.5][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bartlett_stopwords = ' '.join(bartlett).replace('.', '').replace(',', '').split()\n",
    "\n",
    "for temp in [0.1,0.5,1.0,1.5,2.0]:\n",
    "    print(\"Temperature = {}:\".format(temp))\n",
    "    items = [item[0] for item in generated['set_1'][temp]]\n",
    "    text = ' '.join(items)\n",
    "\n",
    "    wordcloud = WordCloud(width=600, height=400, background_color=\"white\", max_font_size=50, stopwords=bartlett_stopwords).generate(text)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
